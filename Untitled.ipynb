{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbookpro/Documents/5. Kaggle/Iowa Housing Price Prediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iowa_file_path = '/Users/macbookpro/Documents/5. Kaggle/Iowa Housing Price Prediction/train.csv'\n",
    "X_full = pd.read_csv(iowa_file_path)\n",
    "\n",
    "test_data_path = '/Users/macbookpro/Documents/5. Kaggle/Iowa Housing Price Prediction/test.csv'\n",
    "X_test_full = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the list of columns in the dataset to find the name of the prediction target\n",
    "home_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select SalePrice as prediction target\n",
    "y = X_full.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features for prediction\n",
    "features = [\"LotArea\",\"YearBuilt\",\"1stFlrSF\",\"2ndFlrSF\",\"FullBath\",\"BedroomAbvGr\",\"TotRmsAbvGrd\"]\n",
    "\n",
    "# create X as the set of independent variables to generate prediction\n",
    "X = X_full[features].copy()\n",
    "X_test = X_test_full[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      #random_state=0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=1, splitter='best')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify and fit a decision tree model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "iowa_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions with the validation dataset\n",
    "val_predictions = iowa_model.predict(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186500. 184000. 130000.  92000. 164500.]\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# print the top few validation predictions\n",
    "print(iowa_model.predict(X_valid.head()))\n",
    "# print the top few actual prices from validation data\n",
    "print(home_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29652.931506849316\n"
     ]
    }
   ],
   "source": [
    "#Calculate the Mean Absolute Error in Validation Data\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "val_mae = mean_absolute_error(y_valid, val_predictions)\n",
    "\n",
    "# uncomment following line to see the validation_mae\n",
    "print(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHECKING FOR UNDERFITTING/OVERFITTING'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"MODEL OPTIMIZATION\"\"\"\n",
    "\"\"\"CHECKING FOR UNDERFITTING/OVERFITTING\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, X_train, X_valid, y_train, y_valid):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_val = model.predict(X_valid)\n",
    "    mae = mean_absolute_error(y_valid, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  35044\n",
      "Max leaf nodes: 25  \t\t Mean Absolute Error:  29016\n",
      "Max leaf nodes: 50  \t\t Mean Absolute Error:  27405\n",
      "Max leaf nodes: 100  \t\t Mean Absolute Error:  27282\n",
      "Max leaf nodes: 250  \t\t Mean Absolute Error:  27893\n",
      "Max leaf nodes: 500  \t\t Mean Absolute Error:  29454\n",
      "Optimal nodes: 100 Best MAE: 27282.50803885739\n"
     ]
    }
   ],
   "source": [
    "#Loop that tries the following values for *max_leaf_nodes* from a set of possible values.\n",
    "\n",
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "\n",
    "# Find the ideal tree size from candidate_max_leaf_nodes\n",
    "\n",
    "min_mae = 1000000\n",
    "for max_leaf_nodes in candidate_max_leaf_nodes:\n",
    "    my_mae = get_mae(max_leaf_nodes, X_train, X_valid, y_train, y_valid)\n",
    "    if my_mae < min_mae:\n",
    "        min_mae = my_mae\n",
    "        best_leaf_n_nodes = max_leaf_nodes\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))\n",
    "print(\"Optimal nodes:\", best_leaf_n_nodes, \"Best MAE:\", min_mae)\n",
    "\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "best_tree_size = best_leaf_n_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IMPROVING THE MODEL USING RANDOM FOREST'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"IMPROVING THE MODEL USING RANDOM FOREST\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating and fitting a random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Random Forest Model: 21857.15912981083\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean absolute error of the model on the validation data\n",
    "rf_val_predictions = rf_model.predict(X_valid)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, y_valid)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different random forest models\n",
    "\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=1)\n",
    "model_2 = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "model_3 = RandomForestRegressor(n_estimators=100, criterion='mae', random_state=1)\n",
    "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=1)\n",
    "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=1)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 MAE: 22024\n",
      "Model 2 MAE: 21857\n",
      "Model 3 MAE: 21878\n",
      "Model 4 MAE: 22669\n",
      "Model 5 MAE: 22352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function for comparing different models\n",
    "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "for i in range(0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    print(\"Model %d MAE: %d\" % (i+1, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GENERATE PREDICTIONS FOR THE TEST DATASET\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "best_model.fit(X, y)\n",
    "preds_test = best_model.predict(X_test)\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CREATE A MODEL INCLUDING ALL VARIABLES AND WORKING ON CATERGORICAL VARIABLES\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 62)\n",
      "(1459, 61)\n"
     ]
    }
   ],
   "source": [
    "X = X_full\n",
    "X_test = X_test_full\n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 61)\n",
      "(1459, 61)\n"
     ]
    }
   ],
   "source": [
    "# To keep things simple, we'll drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>807</td>\n",
       "      <td>808</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>21384</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>955</td>\n",
       "      <td>956</td>\n",
       "      <td>90</td>\n",
       "      <td>RH</td>\n",
       "      <td>7136</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1041</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13125</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>701</td>\n",
       "      <td>702</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotArea Street LotShape LandContour  \\\n",
       "6        7          20       RL    10084   Pave      Reg         Lvl   \n",
       "807    808          70       RL    21384   Pave      Reg         Lvl   \n",
       "955    956          90       RH     7136   Pave      IR1         HLS   \n",
       "1040  1041          20       RL    13125   Pave      Reg         Lvl   \n",
       "701    702          20       RL     9600   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "6       AllPub    Inside       Gtl  ...          57             0         0   \n",
       "807     AllPub    Inside       Gtl  ...         312             0         0   \n",
       "955     AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1040    AllPub    Corner       Gtl  ...           0             0         0   \n",
       "701     AllPub    Inside       Gtl  ...           0             0         0   \n",
       "\n",
       "     ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "6              0        0        0       8    2007        WD        Normal  \n",
       "807            0        0        0       5    2009        WD        Normal  \n",
       "955            0        0        0       8    2007        WD        Normal  \n",
       "1040           0        0        0       1    2006        WD        Normal  \n",
       "701            0        0        0       7    2006       COD        Normal  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To compare different models, you'll use the same `score_dataset()` function.  \n",
    "#This function reports the mean absolute error (MAE) from a random forest model.\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17006.18194520548\n"
     ]
    }
   ],
   "source": [
    "#Approach 1: Drop columns with categorical data\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosN' 'Artery' 'RRNn' 'Feedr' 'RRAe' 'PosA']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'Feedr' 'RRAn']\n"
     ]
    }
   ],
   "source": [
    "#Approach 2: Label encoding\n",
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be label encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType', 'HouseStyle', 'RoofStyle', 'ExterQual', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Exterior1st', 'Condition1', 'Foundation', 'Utilities', 'Exterior2nd', 'Heating', 'Condition2', 'RoofMatl', 'SaleType', 'Functional', 'HeatingQC', 'ExterCond']\n"
     ]
    }
   ],
   "source": [
    "#The code cell below saves the problematic columns to a Python list `bad_label_cols`.  \n",
    "#Likewise, columns that can be safely label encoded are stored in `good_label_cols`.\n",
    "\n",
    "# All categorical columns\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_train[col]) == set(X_valid[col])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Label Encoding):\n",
      "16558.780493150687\n"
     ]
    }
   ],
   "source": [
    "#Execute label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply label encoder \n",
    "label_encoder = LabelEncoder()\n",
    "for col in set(good_label_cols):\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "    \n",
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('HeatingQC', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('Condition2', 7),\n",
       " ('RoofMatl', 7),\n",
       " ('Functional', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 14),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Approach 3: One-hot encoding\n",
    "\n",
    "#First it is important to investigate the cardinality of the categorical variables\n",
    "#For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset.  \n",
    "#For this reason, we typically will only one-hot encode columns with relatively low cardinality.  \n",
    "#Then, high cardinality columns can either be dropped from the dataset, or we can use label encoding.\n",
    "\n",
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Exterior1st', 'Neighborhood', 'Exterior2nd']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "16618.080904109585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EXECUTING CROSS VALIDATION\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "iowa_file_path = '/Users/macbookpro/Documents/5. Kaggle/Iowa Housing Price Prediction/train.csv'\n",
    "train_data = pd.read_csv(iowa_file_path)\n",
    "\n",
    "test_data_path = '/Users/macbookpro/Documents/5. Kaggle/Iowa Housing Price Prediction/test.csv'\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = train_data.SalePrice              \n",
    "train_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\n",
    "X = train_data[numeric_cols].copy()\n",
    "X_test = test_data[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple imputer to replace missing values in the data\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score: 18236.997273972604\n"
     ]
    }
   ],
   "source": [
    "#function to obtain the mean absolute error (MAE), averaged across five different folds.  \n",
    "#Recall we set the number of folds with the `cv` (cross-validation) parameter.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators): #n_estimators -- the number of trees in the forest\n",
    "    \n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
    "                              ('model', RandomForestRegressor(n_estimators,\n",
    "                                                              random_state=1))\n",
    "                             ])\n",
    "\n",
    "    scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=3,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of trees in forest: 400\n",
      "MAE: 18317.56456954549\n",
      "dict_keys([50, 100, 150, 200, 250, 300, 350, 400])\n",
      "dict_values([18771.9253745532, 18466.944964622013, 18374.86285366488, 18392.40787463066, 18377.063023725223, 18341.08233706455, 18333.76093771792, 18317.56456954549])\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model performance corresponding to eight different values for the number of trees in the random forest: \n",
    "#50, 100, 150, ..., 300, 350, 400.\n",
    "\n",
    "results = {}\n",
    "min_score=10000000\n",
    "for i in range(1,9):\n",
    "    results[50*i] = get_score(50*i)\n",
    "    if get_score(50*i) < min_score:\n",
    "        min_score=get_score(50*i)\n",
    "\n",
    "n_estimators_best = min(results, key=results.get)\n",
    "\n",
    "print('Best number of trees in forest:', n_estimators_best)\n",
    "print('MAE:', min_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
